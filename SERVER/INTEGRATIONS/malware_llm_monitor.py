#!/usr/bin/env python3

import json
import logging
import subprocess
import traceback
import time
from datetime import datetime
from openai import OpenAI

# Configuration
ALERTS_FILE = "/var/ossec/logs/alerts/alerts.json"
LOG_FILE = "/var/ossec/logs/malware.log"
SUMMARY_FILE = "/var/ossec/logs/malware_summary.log"
TARGET_RULES = ["62123", "62124"]
CHECK_INTERVAL = 60  # Time in seconds between checks

# Novita AI Configuration
API_KEY = "sk_-g5Syzji65lYDICI3v4Wtmw7rQAetiM7-h0wdk7Qw78"
BASE_URL = "https://api.novita.ai/v3/openai"
MODEL = "deepseek/deepseek-v3-turbo"

# Setup logging
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('malware_llm')

def extract_malware_fields(alert):
    """Extract the specified fields from the alert"""
    try:
        # Handle different JSON structures in the alert
        if '_source' in alert:
            source = alert['_source']
            # Extract alert ID from the original structure
            alert_id = alert.get('_id', alert.get('id', source.get('id', 'Unknown')))
        else:
            source = alert
            # Extract alert ID from the flat structure
            alert_id = alert.get('id', 'Unknown')

        # Extract all the specified fields
        agent = source.get('agent', {})
        win_data = source.get('data', {}).get('win', {})
        eventdata = win_data.get('eventdata', {})
        system = win_data.get('system', {})
        rule = source.get('rule', {})

        # Create a structured object with all the requested fields
        fields = {
           # "id": alert_id,  # Add the alert ID at the top level
            "agent": {
                "id": agent.get('id', 'Unknown'),
                "ip": agent.get('ip', 'Unknown'),
                "name": agent.get('name', 'Unknown')
            },
            "data": {
                "win": {
                    "eventdata": {
                        "action_Name": eventdata.get('action Name', 'Unknown'),
                        "additional_Actions_String": eventdata.get('additional Actions String', 'Unknown'),
                        "category_Name": eventdata.get('category Name', 'Unknown'),
                        "detection_Time": eventdata.get('detection Time', 'Unknown'),
                        "detection_User": eventdata.get('detection User', 'Unknown'),
                        "path": eventdata.get('path', 'Unknown'),
                        "process_Name": eventdata.get('process Name', 'Unknown'),
                        "product_Name": "CyberSentinel Threat Management",
                        "remediation_User": eventdata.get('remediation User', 'Unknown'),
                        "severity_ID": eventdata.get('severity ID', 'Unknown'),
                        "severity_Name": eventdata.get('severity Name', 'Unknown'),
                        "source_Name": eventdata.get('source Name', 'Unknown'),
                        "threat_Name": eventdata.get('threat Name', 'Unknown')
                    },
                    "system": {
                        "computer": system.get('computer', 'Unknown'),
                        "processID": system.get('processID', 'Unknown'),
                        "systemTime": system.get('systemTime', 'Unknown'),
                        "threadID": system.get('threadID', 'Unknown')
                    }
                }
            },
            "rule": {
                "id": "100100",
                "level": rule.get('level', 'Unknown'),
                "description": "CTM has performed an action to protect you from potentially unwanted software."
            }
        }

        return fields

    except Exception as e:
        logger.error(f"Error extracting malware fields: {e}")
        logger.error(traceback.format_exc())
        return None

def get_llm_analysis(malware_fields):
    """Get malware analysis from Novita AI LLM using OpenAI client"""
    try:
        threat_name = malware_fields['data']['win']['eventdata']['threat_Name']
        category = malware_fields['data']['win']['eventdata']['category_Name']
        severity = malware_fields['data']['win']['eventdata']['severity_Name']

        logger.info(f"Getting LLM analysis for {threat_name}")

        # Initialize the OpenAI client with Novita AI configuration
        client = OpenAI(
            base_url=BASE_URL,
            api_key=API_KEY,
        )

        # Create system prompt for malware analysis
        system_content = """You are a cybersecurity expert specializing in malware analysis.
        Provide concise, informative analysis focused on what the malware does, how it spreads,
        potential impact, and recommended actions. Limit your response to 4-5 lines."""

        # Create user prompt with malware information
        user_content = f"""Analyze this malware:
        Name: {threat_name}
        Category: {category}
        Severity: {severity}

        Provide a 5-6 line summary covering: functionality, infection methods, potential impact, and recommended actions."""

        # Call the LLM API
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": system_content,
                },
                {
                    "role": "user",
                    "content": user_content,
                }
            ],
            stream=False,
            max_tokens=300,
            temperature=0.7,
            top_p=1,
            presence_penalty=0,
            frequency_penalty=0,
            response_format={"type": "text"},
            extra_body={
                "top_k": 50,
                "repetition_penalty": 1,
                "min_p": 0
            }
        )

        # Extract the response text
        analysis = response.choices[0].message.content.strip()
        logger.info(f"Successfully received LLM analysis")
        return analysis

    except Exception as e:
        logger.error(f"Error in LLM analysis: {e}")
        logger.error(traceback.format_exc())
        return f"Error generating malware analysis: {str(e)}"

def process_alert_line(line):
    """Process a single alert line"""
    try:
        # Parse the JSON alert
        alert = json.loads(line)

        # Check if this is a target rule
        rule_id = alert.get('rule', {}).get('id')
        if not rule_id and '_source' in alert:
            rule_id = alert.get('_source', {}).get('rule', {}).get('id')

        if rule_id not in TARGET_RULES:
            return

        # Extract malware fields
        malware_fields = extract_malware_fields(alert)
        if not malware_fields:
            logger.error(f"Failed to extract malware fields from alert")
            return

        # Log what we're about to process
        agent_name = malware_fields['agent']['name']
        threat_name = malware_fields['data']['win']['eventdata']['threat_Name']
        logger.info(f"Processing malware alert - Agent: {agent_name}, Threat: {threat_name}")

        # Get LLM analysis
        analysis = get_llm_analysis(malware_fields)

        # Add the LLM analysis under the 'data' key
        if 'data' in malware_fields:
            malware_fields['data']['AI_response'] = analysis
        else:
            malware_fields['data'] = {'AI_response': analysis}

        # Add timestamp for the log entry
        malware_fields['log_timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # Write to JSON summary file
        with open(SUMMARY_FILE, 'a') as f:
            f.write(json.dumps(malware_fields) + "\n")

        logger.info(f"Successfully wrote enriched alert to {SUMMARY_FILE}")

    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON: {e}")
    except Exception as e:
        logger.error(f"Error processing alert: {e}")
        logger.error(traceback.format_exc())

def process_existing_alerts():
    """Process existing alerts with target rule IDs"""
    logger.info("Processing existing alerts...")

    try:
        # Keep track of processed alerts to avoid duplicates
        processed_alerts = set()

        # Get the last processed timestamp
        try:
            with open('/var/ossec/tmp/last_processed_time.txt', 'r') as f:
                last_time = float(f.read().strip())
        except (FileNotFoundError, ValueError):
            last_time = 0

        current_time = time.time()

        # Find all alerts for each target rule ID
        for rule_id in TARGET_RULES:
            # Use grep to extract relevant alerts
            cmd = f"grep -F '\"id\":\"{rule_id}\"' {ALERTS_FILE}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

            for line in result.stdout.splitlines():
                try:
                    # Check if this is a new alert
                    alert = json.loads(line)
                    alert_id = alert.get('id')

                    # Skip if already processed
                    if alert_id in processed_alerts:
                        continue

                    # Add to processed set
                    processed_alerts.add(alert_id)

                    # Get alert timestamp
                    if '_source' in alert and 'timestamp' in alert['_source']:
                        timestamp_str = alert['_source']['timestamp']
                    elif 'timestamp' in alert:
                        timestamp_str = alert['timestamp']
                    else:
                        # Process anyway if no timestamp found
                        process_alert_line(line)
                        continue

                    # Convert timestamp to epoch time
                    try:
                        # Handle various timestamp formats
                        if 'T' in timestamp_str:
                            # Handle timezone information
                            if '+' in timestamp_str and not timestamp_str.endswith('+00:00'):
                                # Parse timestamps like '2025-04-22T10:29:24.289+0530'
                                dt = datetime.strptime(timestamp_str, '%Y-%m-%dT%H:%M:%S.%f%z')
                            elif 'Z' in timestamp_str:
                                # Parse UTC timestamps with Z suffix
                                dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                            else:
                                # Parse other ISO format timestamps
                                dt = datetime.fromisoformat(timestamp_str)
                        else:
                            # Parse simple datetime format
                            dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')

                        alert_time = dt.timestamp()

                        # Process only new alerts
                        if alert_time > last_time:
                            process_alert_line(line)
                    except ValueError as e:
                        # Log the specific parsing error
                        logger.warning(f"Error parsing timestamp '{timestamp_str}': {e}")
                        # Process anyway if timestamp parsing fails
                        process_alert_line(line)

                except json.JSONDecodeError:
                    continue

        # Save the current time as the last processed time
        with open('/var/ossec/tmp/last_processed_time.txt', 'w') as f:
            f.write(str(current_time))

    except Exception as e:
        logger.error(f"Error processing existing alerts: {e}")
        logger.error(traceback.format_exc())

def run_continuously():
    """Run the alert processor in a continuous loop"""
    logger.info("Starting continuous monitoring mode")

    while True:
        try:
            # Process existing alerts
            process_existing_alerts()

            # Sleep for a specified interval before checking again
            logger.info(f"Sleeping for {CHECK_INTERVAL} seconds before next check")
            time.sleep(CHECK_INTERVAL)

        except KeyboardInterrupt:
            logger.info("Received keyboard interrupt, exiting")
            break
        except Exception as e:
            logger.error(f"Error in monitoring loop: {e}")
            logger.error(traceback.format_exc())
            # Sleep briefly before retrying to avoid tight error loops
            time.sleep(5)

if __name__ == "__main__":
    logger.info("===== Starting Malware LLM Analyzer =====")

    # Run in continuous mode
    run_continuously()
